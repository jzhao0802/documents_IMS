{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Runing XGBoost Model in mlr Package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in the relevant packages and setup the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ParamHelpers\n",
      "\n",
      "Attaching package: 'dplyr'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Loading required package: gplots\n",
      "\n",
      "Attaching package: 'gplots'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    lowess\n",
      "\n",
      "\n",
      "Attaching package: 'ROCR'\n",
      "\n",
      "The following object is masked from 'package:mlr':\n",
      "\n",
      "    performance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(mlr)\n",
    "library(readr)\n",
    "library(dplyr)\n",
    "library(parallel)\n",
    "library(ROCR)\n",
    "library(parallelMap)\n",
    "setwd(\"D:/Project_2017/Training_0331\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Reading in the data and define the Learning Task\n",
    "#### The data is the Titanic survival data which is from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df <- readr::read_csv(\"./data_for_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>y</th><th scope=col>Pclass</th><th scope=col>Sex</th><th scope=col>Age</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Fare</th><th scope=col>Embarked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0       </td><td>1       </td><td>1       </td><td>40.0    </td><td>0       </td><td>0       </td><td> 27.7208</td><td>0       </td></tr>\n",
       "\t<tr><td>1       </td><td>1       </td><td>0       </td><td>29.9    </td><td>1       </td><td>0       </td><td>146.5208</td><td>0       </td></tr>\n",
       "\t<tr><td>0       </td><td>2       </td><td>1       </td><td>66.0    </td><td>0       </td><td>0       </td><td> 10.5000</td><td>2       </td></tr>\n",
       "\t<tr><td>0       </td><td>1       </td><td>1       </td><td>42.0    </td><td>1       </td><td>0       </td><td> 52.0000</td><td>2       </td></tr>\n",
       "\t<tr><td>1       </td><td>2       </td><td>0       </td><td> 5.0    </td><td>1       </td><td>2       </td><td> 27.7500</td><td>2       </td></tr>\n",
       "\t<tr><td>1       </td><td>3       </td><td>1       </td><td>29.9    </td><td>1       </td><td>1       </td><td> 15.2458</td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " y & Pclass & Sex & Age & SibSp & Parch & Fare & Embarked\\\\\n",
       "\\hline\n",
       "\t 0        & 1        & 1        & 40.0     & 0        & 0        &  27.7208 & 0       \\\\\n",
       "\t 1        & 1        & 0        & 29.9     & 1        & 0        & 146.5208 & 0       \\\\\n",
       "\t 0        & 2        & 1        & 66.0     & 0        & 0        &  10.5000 & 2       \\\\\n",
       "\t 0        & 1        & 1        & 42.0     & 1        & 0        &  52.0000 & 2       \\\\\n",
       "\t 1        & 2        & 0        &  5.0     & 1        & 2        &  27.7500 & 2       \\\\\n",
       "\t 1        & 3        & 1        & 29.9     & 1        & 1        &  15.2458 & 0       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "y | Pclass | Sex | Age | SibSp | Parch | Fare | Embarked | \n",
       "|---|---|---|---|---|---|\n",
       "| 0        | 1        | 1        | 40.0     | 0        | 0        |  27.7208 | 0        | \n",
       "| 1        | 1        | 0        | 29.9     | 1        | 0        | 146.5208 | 0        | \n",
       "| 0        | 2        | 1        | 66.0     | 0        | 0        |  10.5000 | 2        | \n",
       "| 0        | 1        | 1        | 42.0     | 1        | 0        |  52.0000 | 2        | \n",
       "| 1        | 2        | 0        |  5.0     | 1        | 2        |  27.7500 | 2        | \n",
       "| 1        | 3        | 1        | 29.9     | 1        | 1        |  15.2458 | 0        | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  y Pclass Sex Age  SibSp Parch Fare     Embarked\n",
       "1 0 1      1   40.0 0     0      27.7208 0       \n",
       "2 1 1      0   29.9 1     0     146.5208 0       \n",
       "3 0 2      1   66.0 0     0      10.5000 2       \n",
       "4 0 1      1   42.0 1     0      52.0000 2       \n",
       "5 1 2      0    5.0 1     2      27.7500 2       \n",
       "6 1 3      1   29.9 1     1      15.2458 0       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:  Defining the Learning Tasks\n",
    "#### Intro to learning tasks\n",
    "- Learning tasks encapsulate the data set and further relevant information about a machine learning problem.\n",
    "- The following tasks can be instanitated and all inherit from the virtual superclass Task:\n",
    "    - *RegrTask*: for regression problems\n",
    "    - *ClassifTask*: for binary and multi-class classification problems\n",
    "    - *SurvTask*: for survival analysis\n",
    "    - *ClusterTask*: for cluster analysis\n",
    "    - *MultilabelTask*: for multilabel classification problems\n",
    "    - *CostSensTask*: for general cost-sensitive classification\n",
    "- To create a task, just call `make<TaskType>`, e.g. `makeClassifTask`\n",
    "- All tasks require an identifier(argument `id`) and a data.frame(argument `data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 <- as.data.frame(df)\n",
    "dataset <- makeClassifTask(id=\"xgb_mlr_eg\", data=df2, target=\"y\", positive=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing a learning task\n",
    "- `getTaskDescription()` contains basic information about the task you can use\n",
    "- Frequently  required elements can also be accessed directly\n",
    "    - `getTaskId()`\n",
    "    - `getTaskType()`\n",
    "    - `getTaskSize()`\n",
    "    - etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$id\n",
       "[1] \"xgb_mlr_eg\"\n",
       "\n",
       "$type\n",
       "[1] \"classif\"\n",
       "\n",
       "$target\n",
       "[1] \"y\"\n",
       "\n",
       "$size\n",
       "[1] 1309\n",
       "\n",
       "$n.feat\n",
       "numerics  factors  ordered \n",
       "       7        0        0 \n",
       "\n",
       "$has.missings\n",
       "[1] FALSE\n",
       "\n",
       "$has.weights\n",
       "[1] FALSE\n",
       "\n",
       "$has.blocking\n",
       "[1] FALSE\n",
       "\n",
       "$class.levels\n",
       "[1] \"0\" \"1\"\n",
       "\n",
       "$positive\n",
       "[1] \"1\"\n",
       "\n",
       "$negative\n",
       "[1] \"0\"\n",
       "\n",
       "attr(,\"class\")\n",
       "[1] \"TaskDescClassif\"    \"TaskDescSupervised\" \"TaskDesc\"          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getTaskDescription(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modifying a learning task\n",
    "- `subsetTask()` to select observations and/or features\n",
    "- `removeConstanctFeatures()` to remove features that is a contant\n",
    "- `dropFeatures()` to remove selected features\n",
    "- `normalizeFeatures()` to standardize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " y           Pclass            Sex             Age             SibSp        \n",
       " 0:826   Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1:483   1st Qu.:0.5000   1st Qu.:0.000   1st Qu.:0.2735   1st Qu.:0.00000  \n",
       "         Median :1.0000   Median :1.000   Median :0.3724   Median :0.00000  \n",
       "         Mean   :0.6474   Mean   :0.644   Mean   :0.3722   Mean   :0.06236  \n",
       "         3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:0.4363   3rd Qu.:0.12500  \n",
       "         Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.00000  \n",
       "     Parch              Fare            Embarked     \n",
       " Min.   :0.00000   Min.   :0.00000   Min.   :0.0000  \n",
       " 1st Qu.:0.00000   1st Qu.:0.01541   1st Qu.:0.5000  \n",
       " Median :0.00000   Median :0.02821   Median :1.0000  \n",
       " Mean   :0.04278   Mean   :0.06499   Mean   :0.7468  \n",
       " 3rd Qu.:0.00000   3rd Qu.:0.06104   3rd Qu.:1.0000  \n",
       " Max.   :1.00000   Max.   :1.00000   Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_task <- normalizeFeatures(dataset, method='range')\n",
    "summary(getTaskData(norm_task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Constructing a learner\n",
    "#### Define a learner\n",
    "- A learner in `mlr` is generated by calling `makeLearner`. In the constructor you need to specify which learning method you want to use, which hyper-parameter space you would like to search and which kind of output you need.\n",
    "- In our classification case, we need to setup the learner by:\n",
    "    - The first argument specifies which algorithm to use, the naming convention is `clssif.<R_method_name>` for classification methods.\n",
    "    - The second argument specifies the output for later prediction, i.e. whether a factor of predicted class labels or probabilities\n",
    "    - Hyperparameters can be specified either via the `...` argument or as a list var `par.vals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrn <- makeLearner(\"classif.xgboost\", predict.type=\"prob\")\n",
    "lrn$par.vals = list(\n",
    "  nrounds = 100,\n",
    "  verbose = F,\n",
    "  objective = \"binary:logistic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner classif.xgboost from package xgboost\n",
       "Type: classif\n",
       "Name: eXtreme Gradient Boosting; Short name: xgboost\n",
       "Class: classif.xgboost\n",
       "Properties: twoclass,multiclass,numerics,factors,prob,weights,missings,featimp\n",
       "Predict-Type: prob\n",
       "Hyperparameters: nrounds=100,verbose=FALSE,objective=binary:logistic\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing a learner\n",
    "- The learner object has a list and following elements contain info regarding the hyperparameters and the type of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$nrounds</dt>\n",
       "\t\t<dd>100</dd>\n",
       "\t<dt>$verbose</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary:logistic'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$nrounds] 100\n",
       "\\item[\\$verbose] FALSE\n",
       "\\item[\\$objective] 'binary:logistic'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$nrounds\n",
       ":   100\n",
       "$verbose\n",
       ":   FALSE\n",
       "$objective\n",
       ":   'binary:logistic'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$nrounds\n",
       "[1] 100\n",
       "\n",
       "$verbose\n",
       "[1] FALSE\n",
       "\n",
       "$objective\n",
       "[1] \"binary:logistic\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn$par.vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The slot `$par.set` is an object of class ParamSet. It contains potential default values and the range of allowed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          Type len             Def               Constr Req\n",
       "booster               discrete   -          gbtree gbtree,gblinear,dart   -\n",
       "silent                 integer   -               0          -Inf to Inf   -\n",
       "eta                    numeric   -             0.3               0 to 1   -\n",
       "gamma                  numeric   -               0             0 to Inf   -\n",
       "max_depth              integer   -               6             1 to Inf   -\n",
       "min_child_weight       numeric   -               1             0 to Inf   -\n",
       "subsample              numeric   -               1               0 to 1   -\n",
       "colsample_bytree       numeric   -               1               0 to 1   -\n",
       "colsample_bylevel      numeric   -               1               0 to 1   -\n",
       "num_parallel_tree      integer   -               1             1 to Inf   -\n",
       "lambda                 numeric   -               0             0 to Inf   -\n",
       "lambda_bias            numeric   -               0             0 to Inf   -\n",
       "alpha                  numeric   -               0             0 to Inf   -\n",
       "objective              untyped   - binary:logistic                    -   -\n",
       "eval_metric            untyped   -           error                    -   -\n",
       "base_score             numeric   -             0.5          -Inf to Inf   -\n",
       "max_delta_step         numeric   -               0             0 to Inf   -\n",
       "missing                numeric   -          <NULL>          -Inf to Inf   -\n",
       "nthread                integer   -               -             1 to Inf   -\n",
       "nrounds                integer   -               1             1 to Inf   -\n",
       "feval                  untyped   -          <NULL>                    -   -\n",
       "verbose                integer   -               1               0 to 2   -\n",
       "print_every_n          integer   -               1             1 to Inf   Y\n",
       "early_stopping_rounds  integer   -          <NULL>             1 to Inf   -\n",
       "maximize               logical   -          <NULL>                    -   -\n",
       "sample_type           discrete   -         uniform     uniform,weighted   Y\n",
       "normalize_type        discrete   -            tree          tree,forest   Y\n",
       "rate_drop              numeric   -               0               0 to 1   Y\n",
       "skip_drop              numeric   -               0               0 to 1   Y\n",
       "                      Tunable Trafo\n",
       "booster                  TRUE     -\n",
       "silent                  FALSE     -\n",
       "eta                      TRUE     -\n",
       "gamma                    TRUE     -\n",
       "max_depth                TRUE     -\n",
       "min_child_weight         TRUE     -\n",
       "subsample                TRUE     -\n",
       "colsample_bytree         TRUE     -\n",
       "colsample_bylevel        TRUE     -\n",
       "num_parallel_tree        TRUE     -\n",
       "lambda                   TRUE     -\n",
       "lambda_bias              TRUE     -\n",
       "alpha                    TRUE     -\n",
       "objective               FALSE     -\n",
       "eval_metric             FALSE     -\n",
       "base_score              FALSE     -\n",
       "max_delta_step           TRUE     -\n",
       "missing                 FALSE     -\n",
       "nthread                 FALSE     -\n",
       "nrounds                  TRUE     -\n",
       "feval                   FALSE     -\n",
       "verbose                 FALSE     -\n",
       "print_every_n           FALSE     -\n",
       "early_stopping_rounds   FALSE     -\n",
       "maximize                FALSE     -\n",
       "sample_type              TRUE     -\n",
       "normalize_type           TRUE     -\n",
       "rate_drop                TRUE     -\n",
       "skip_drop                TRUE     -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn$par.set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function `getHyperPars` access the current hyperparameter setting of a learner and `getParamSet` access to get a description of all possible settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$nrounds</dt>\n",
       "\t\t<dd>100</dd>\n",
       "\t<dt>$verbose</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$objective</dt>\n",
       "\t\t<dd>'binary:logistic'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$nrounds] 100\n",
       "\\item[\\$verbose] FALSE\n",
       "\\item[\\$objective] 'binary:logistic'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$nrounds\n",
       ":   100\n",
       "$verbose\n",
       ":   FALSE\n",
       "$objective\n",
       ":   'binary:logistic'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$nrounds\n",
       "[1] 100\n",
       "\n",
       "$verbose\n",
       "[1] FALSE\n",
       "\n",
       "$objective\n",
       "[1] \"binary:logistic\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getHyperPars(lrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          Type len             Def               Constr Req\n",
       "booster               discrete   -          gbtree gbtree,gblinear,dart   -\n",
       "silent                 integer   -               0          -Inf to Inf   -\n",
       "eta                    numeric   -             0.3               0 to 1   -\n",
       "gamma                  numeric   -               0             0 to Inf   -\n",
       "max_depth              integer   -               6             1 to Inf   -\n",
       "min_child_weight       numeric   -               1             0 to Inf   -\n",
       "subsample              numeric   -               1               0 to 1   -\n",
       "colsample_bytree       numeric   -               1               0 to 1   -\n",
       "colsample_bylevel      numeric   -               1               0 to 1   -\n",
       "num_parallel_tree      integer   -               1             1 to Inf   -\n",
       "lambda                 numeric   -               0             0 to Inf   -\n",
       "lambda_bias            numeric   -               0             0 to Inf   -\n",
       "alpha                  numeric   -               0             0 to Inf   -\n",
       "objective              untyped   - binary:logistic                    -   -\n",
       "eval_metric            untyped   -           error                    -   -\n",
       "base_score             numeric   -             0.5          -Inf to Inf   -\n",
       "max_delta_step         numeric   -               0             0 to Inf   -\n",
       "missing                numeric   -          <NULL>          -Inf to Inf   -\n",
       "nthread                integer   -               -             1 to Inf   -\n",
       "nrounds                integer   -               1             1 to Inf   -\n",
       "feval                  untyped   -          <NULL>                    -   -\n",
       "verbose                integer   -               1               0 to 2   -\n",
       "print_every_n          integer   -               1             1 to Inf   Y\n",
       "early_stopping_rounds  integer   -          <NULL>             1 to Inf   -\n",
       "maximize               logical   -          <NULL>                    -   -\n",
       "sample_type           discrete   -         uniform     uniform,weighted   Y\n",
       "normalize_type        discrete   -            tree          tree,forest   Y\n",
       "rate_drop              numeric   -               0               0 to 1   Y\n",
       "skip_drop              numeric   -               0               0 to 1   Y\n",
       "                      Tunable Trafo\n",
       "booster                  TRUE     -\n",
       "silent                  FALSE     -\n",
       "eta                      TRUE     -\n",
       "gamma                    TRUE     -\n",
       "max_depth                TRUE     -\n",
       "min_child_weight         TRUE     -\n",
       "subsample                TRUE     -\n",
       "colsample_bytree         TRUE     -\n",
       "colsample_bylevel        TRUE     -\n",
       "num_parallel_tree        TRUE     -\n",
       "lambda                   TRUE     -\n",
       "lambda_bias              TRUE     -\n",
       "alpha                    TRUE     -\n",
       "objective               FALSE     -\n",
       "eval_metric             FALSE     -\n",
       "base_score              FALSE     -\n",
       "max_delta_step           TRUE     -\n",
       "missing                 FALSE     -\n",
       "nthread                 FALSE     -\n",
       "nrounds                  TRUE     -\n",
       "feval                   FALSE     -\n",
       "verbose                 FALSE     -\n",
       "print_every_n           FALSE     -\n",
       "early_stopping_rounds   FALSE     -\n",
       "maximize                FALSE     -\n",
       "sample_type              TRUE     -\n",
       "normalize_type           TRUE     -\n",
       "rate_drop                TRUE     -\n",
       "skip_drop                TRUE     -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getParamSet(lrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Also the function `getParamSet` could give us a quick overview about the available hyperparameters and defaults of a learning method without explicityly constructing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          Type len             Def               Constr Req\n",
       "booster               discrete   -          gbtree gbtree,gblinear,dart   -\n",
       "silent                 integer   -               0          -Inf to Inf   -\n",
       "eta                    numeric   -             0.3               0 to 1   -\n",
       "gamma                  numeric   -               0             0 to Inf   -\n",
       "max_depth              integer   -               6             1 to Inf   -\n",
       "min_child_weight       numeric   -               1             0 to Inf   -\n",
       "subsample              numeric   -               1               0 to 1   -\n",
       "colsample_bytree       numeric   -               1               0 to 1   -\n",
       "colsample_bylevel      numeric   -               1               0 to 1   -\n",
       "num_parallel_tree      integer   -               1             1 to Inf   -\n",
       "lambda                 numeric   -               0             0 to Inf   -\n",
       "lambda_bias            numeric   -               0             0 to Inf   -\n",
       "alpha                  numeric   -               0             0 to Inf   -\n",
       "objective              untyped   - binary:logistic                    -   -\n",
       "eval_metric            untyped   -           error                    -   -\n",
       "base_score             numeric   -             0.5          -Inf to Inf   -\n",
       "max_delta_step         numeric   -               0             0 to Inf   -\n",
       "missing                numeric   -          <NULL>          -Inf to Inf   -\n",
       "nthread                integer   -               -             1 to Inf   -\n",
       "nrounds                integer   -               1             1 to Inf   -\n",
       "feval                  untyped   -          <NULL>                    -   -\n",
       "verbose                integer   -               1               0 to 2   -\n",
       "print_every_n          integer   -               1             1 to Inf   Y\n",
       "early_stopping_rounds  integer   -          <NULL>             1 to Inf   -\n",
       "maximize               logical   -          <NULL>                    -   -\n",
       "sample_type           discrete   -         uniform     uniform,weighted   Y\n",
       "normalize_type        discrete   -            tree          tree,forest   Y\n",
       "rate_drop              numeric   -               0               0 to 1   Y\n",
       "skip_drop              numeric   -               0               0 to 1   Y\n",
       "                      Tunable Trafo\n",
       "booster                  TRUE     -\n",
       "silent                  FALSE     -\n",
       "eta                      TRUE     -\n",
       "gamma                    TRUE     -\n",
       "max_depth                TRUE     -\n",
       "min_child_weight         TRUE     -\n",
       "subsample                TRUE     -\n",
       "colsample_bytree         TRUE     -\n",
       "colsample_bylevel        TRUE     -\n",
       "num_parallel_tree        TRUE     -\n",
       "lambda                   TRUE     -\n",
       "lambda_bias              TRUE     -\n",
       "alpha                    TRUE     -\n",
       "objective               FALSE     -\n",
       "eval_metric             FALSE     -\n",
       "base_score              FALSE     -\n",
       "max_delta_step           TRUE     -\n",
       "missing                 FALSE     -\n",
       "nthread                 FALSE     -\n",
       "nrounds                  TRUE     -\n",
       "feval                   FALSE     -\n",
       "verbose                 FALSE     -\n",
       "print_every_n           FALSE     -\n",
       "early_stopping_rounds   FALSE     -\n",
       "maximize                FALSE     -\n",
       "sample_type              TRUE     -\n",
       "normalize_type           TRUE     -\n",
       "rate_drop                TRUE     -\n",
       "skip_drop                TRUE     -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getParamSet('classif.xgboost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing learners\n",
    "- Function `listLearners()` would list everthing in mlr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in listLearners.character(\"classif\", properties = \"prob\"):\n",
      "\"The following learners could not be constructed, probably because their packages are not installed:\n",
      "classif.ada,classif.bartMachine,classif.bdk,classif.blackboost,classif.boosting,classif.bst,classif.C50,classif.clusterSVM,classif.dbnDNN,classif.dcSVM,classif.earth,classif.evtree,classif.extraTrees,classif.fnn,classif.gamboost,classif.gaterSVM,classif.geoDA,classif.glmboost,classif.h2o.deeplearning,classif.h2o.gbm,classif.h2o.glm,classif.h2o.randomForest,classif.hdrda,classif.kknn,classif.LiblineaRL1L2SVC,classif.LiblineaRL1LogReg,classif.LiblineaRL2L1SVC,classif.LiblineaRL2LogReg,classif.LiblineaRL2SVC,classif.LiblineaRMultiClassSVC,classif.linDA,classif.lqa,classif.mda,classif.mlp,classif.neuralnet,classif.nnTrain,classif.nodeHarvest,classif.pamr,classif.penalized.fusedlasso,classif.penalized.lasso,classif.penalized.ridge,classif.plr,classif.quaDA,classif.randomForestSRC,classif.ranger,classif.rda,classif.rFerns,classif.rknn,classif.rotationForest,classif.RRF,classif.rrlda,classif.saeDNN,classif.sda,classif.sparseLDA,classif.xyf,cluster.cmeans,cluster.dbscan,cluster.kmeans,multilabel.randomForestSRC,multilabel.rFerns,regr.bartMachine,regr.bcart,regr.bdk,regr.bgp,regr.bgpllm,regr.blackboost,regr.blm,regr.brnn,regr.bst,regr.btgp,regr.btgpllm,regr.btlm,regr.crs,regr.cubist,regr.earth,regr.elmNN,regr.evtree,regr.extraTrees,regr.fnn,regr.frbs,regr.gamboost,regr.glmboost,regr.GPfit,regr.h2o.deeplearning,regr.h2o.gbm,regr.h2o.glm,regr.h2o.randomForest,regr.kknn,regr.km,regr.laGP,regr.LiblineaRL2L1SVR,regr.LiblineaRL2L2SVR,regr.mars,regr.nodeHarvest,regr.pcr,regr.penalized.fusedlasso,regr.penalized.lasso,regr.penalized.ridge,regr.plsr,regr.randomForestSRC,regr.ranger,regr.rknn,regr.RRF,regr.rsm,regr.slim,regr.xyf,surv.CoxBoost,surv.cv.CoxBoost,surv.gamboost,surv.glmboost,surv.penalized.fusedlasso,surv.penalized.lasso,surv.penalized.ridge,surv.randomForestSRC,surv.ranger\n",
      "Check ?learners to see which packages you need or install mlr with all suggestions.\""
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>class</th><th scope=col>package</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>classif.binomial   </td><td>stats              </td></tr>\n",
       "\t<tr><td>classif.cforest    </td><td>party              </td></tr>\n",
       "\t<tr><td>classif.ctree      </td><td>party              </td></tr>\n",
       "\t<tr><td>classif.cvglmnet   </td><td>glmnet             </td></tr>\n",
       "\t<tr><td>classif.featureless</td><td>mlr                </td></tr>\n",
       "\t<tr><td>classif.gausspr    </td><td>kernlab            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " class & package\\\\\n",
       "\\hline\n",
       "\t classif.binomial    & stats              \\\\\n",
       "\t classif.cforest     & party              \\\\\n",
       "\t classif.ctree       & party              \\\\\n",
       "\t classif.cvglmnet    & glmnet             \\\\\n",
       "\t classif.featureless & mlr                \\\\\n",
       "\t classif.gausspr     & kernlab            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "class | package | \n",
       "|---|---|---|---|---|---|\n",
       "| classif.binomial    | stats               | \n",
       "| classif.cforest     | party               | \n",
       "| classif.ctree       | party               | \n",
       "| classif.cvglmnet    | glmnet              | \n",
       "| classif.featureless | mlr                 | \n",
       "| classif.gausspr     | kernlab             | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  class               package\n",
       "1 classif.binomial    stats  \n",
       "2 classif.cforest     party  \n",
       "3 classif.ctree       party  \n",
       "4 classif.cvglmnet    glmnet \n",
       "5 classif.featureless mlr    \n",
       "6 classif.gausspr     kernlab"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrns <- listLearners(\"classif\", properties = \"prob\") #list classifiers that can output probabilities\n",
    "head(lrns[c(\"class\", \"package\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Tuning \n",
    "#### Specifying the searching space\n",
    "- Create a ParamSet object to define a searching space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Type len Def       Constr Req Tunable Trafo\n",
       "eta              numeric   -   -  0.15 to 0.4   -    TRUE     -\n",
       "max_depth        integer   -   -       3 to 8   -    TRUE     -\n",
       "alpha            numeric   -   -       0 to 1   -    TRUE     -\n",
       "lambda           numeric   -   -    0.25 to 3   -    TRUE     -\n",
       "min_child_weight integer   -   -       2 to 6   -    TRUE     -\n",
       "colsample_bytree numeric   -   -   0.3 to 0.7   -    TRUE     -\n",
       "subsample        numeric   -   - 0.65 to 0.95   -    TRUE     -"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = makeParamSet(\n",
    "  makeNumericParam(\"eta\", lower=0.15, upper=0.4),\n",
    "  makeIntegerParam(\"max_depth\", lower=3, upper=8),\n",
    "  makeNumericParam(\"alpha\", lower=0, upper=1),\n",
    "  makeNumericParam(\"lambda\", lower=0.25, upper=3),\n",
    "  makeIntegerParam(\"min_child_weight\", lower=2, upper=6),\n",
    "  makeNumericParam(\"colsample_bytree\", lower=.3, upper=.7),\n",
    "  makeNumericParam(\"subsample\", lower=.65, upper=.95)\n",
    ")\n",
    "ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the optimization algorithm\n",
    "- A grid search is one of the standard ways to choose an appropriate set of parametes from a given search space, but it is normally very slow.\n",
    "- A random search will randomly choose from the specified values, which might be faster in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tune control: TuneControlRandom\n",
       "Same resampling instance: TRUE\n",
       "Imputation value: <worst>\n",
       "Start: NULL\n",
       "Budget: 30\n",
       "Tune threshold: FALSE\n",
       "Further arguments: maxit=30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ctrl <- makeTuneControlRandom(maxit=30)\n",
    "#ctrl <- makeTuneControlGrid(resolution=15L)\n",
    "ctrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing the tuning\n",
    "- Define a resampling strategy and make note of the performance measure\n",
    "- In our case, I will use 3-fold cross-validation to assess the quality of a specific parameter setting.\n",
    "- The default measure to select best parameters is error rate(`mmce`), but we could also pass other measures or a list of measures to `tuneParams`. The __first__ measure is optimized during tuning, the others are simply evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv <- makeResampleDesc(\"CV\", iters=3) \n",
    "measures_ls <- list(auc, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 Parallelization\n",
    "- mlr will use parallelMap package to do parallelization. parallelMap supports all major parallelization backends: local multicore execution using parallel pacakge, socket and MPI clusters using snow, makeshift SSH-clusters using BatchJobs and high performance computing clusters all using BatchJobs.\n",
    "- All we need to do is selecting a backed of calling one of the `parallelStart*` functions, and call `parallelStop` at the end of script\n",
    "- mlr also offers different parallelization levels for fine grained control over the parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlr: mlr.benchmark, mlr.resample, mlr.selectFeatures, mlr.tuneParams"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parallelGetRegisteredLevels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __`mlr.resample`__: Each resampling iteration (a train / test step) is a parallel job.\n",
    "- __`mlr.benchmark`__: Each experiment \"run this learner on this data set\" is a parallel job.\n",
    "- __`mlr.tuneParams`__: Each evaluation in hyperparameter space \"resample with these parameter settings\" is a parallel job. How many of these can be run independently in parallel, depends on the tuning algorithm. For grid search or random search this is no problem, but for other tuners it depends on how many points are produced in each iteration of the optimization. If a tuner works in a purely sequential fashion, we cannot work magic and the hyperparameter evaluation will also run sequentially. But note that you can still parallelize the underlying resampling.\n",
    "- __`mlr.selectFeatures`__: Each evaluation in feature space \"resample with this feature subset\" is a parallel job. The same comments as for \"mlr.tuneParams\" apply here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting parallelization in mode=socket with cpus=4.\n",
      "[Tune] Started tuning learner classif.xgboost for parameter set:\n",
      "                    Type len Def       Constr Req Tunable Trafo\n",
      "eta              numeric   -   -  0.15 to 0.4   -    TRUE     -\n",
      "max_depth        integer   -   -       3 to 8   -    TRUE     -\n",
      "alpha            numeric   -   -       0 to 1   -    TRUE     -\n",
      "lambda           numeric   -   -    0.25 to 3   -    TRUE     -\n",
      "min_child_weight integer   -   -       2 to 6   -    TRUE     -\n",
      "colsample_bytree numeric   -   -   0.3 to 0.7   -    TRUE     -\n",
      "subsample        numeric   -   - 0.65 to 0.95   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0Imputation value: -0\n",
      "Exporting objects to slaves for mode socket: .mlr.slave.options\n",
      "Mapping in parallel: mode = socket; cpus = 4; elements = 30.\n",
      "[Tune] Result: eta=0.29; max_depth=8; alpha=0.983; lambda=2.99; min_child_weight=2; colsample_bytree=0.391; subsample=0.659 : auc.test.mean=0.907,acc.test.mean=0.869\n",
      "Stopped parallelization. All cleaned up.\n"
     ]
    }
   ],
   "source": [
    "random_seed <- 123\n",
    "set.seed(random_seed, \"L'Ecuyer\")\n",
    "\n",
    "num_cores <- 4\n",
    "\n",
    "\n",
    "parallelStartSocket(num_cores, level=\"mlr.tuneParams\")\n",
    "\n",
    "res <- tuneParams(lrn, dataset, resampling=cv, par.set=ps, control=ctrl, \n",
    "                  show.info=T, measures=measures_ls)\n",
    "parallelStop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 Accessing the tuning results\n",
    "- Access the best hyperparameter setting by `$x` and their estimated performance by `$y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$eta</dt>\n",
       "\t\t<dd>0.290133380866084</dd>\n",
       "\t<dt>$max_depth</dt>\n",
       "\t\t<dd>8</dd>\n",
       "\t<dt>$alpha</dt>\n",
       "\t\t<dd>0.983442870563855</dd>\n",
       "\t<dt>$lambda</dt>\n",
       "\t\t<dd>2.98979504892541</dd>\n",
       "\t<dt>$min_child_weight</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>$colsample_bytree</dt>\n",
       "\t\t<dd>0.39119254149684</dd>\n",
       "\t<dt>$subsample</dt>\n",
       "\t\t<dd>0.659285381001271</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$eta] 0.290133380866084\n",
       "\\item[\\$max\\_depth] 8\n",
       "\\item[\\$alpha] 0.983442870563855\n",
       "\\item[\\$lambda] 2.98979504892541\n",
       "\\item[\\$min\\_child\\_weight] 2\n",
       "\\item[\\$colsample\\_bytree] 0.39119254149684\n",
       "\\item[\\$subsample] 0.659285381001271\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$eta\n",
       ":   0.290133380866084\n",
       "$max_depth\n",
       ":   8\n",
       "$alpha\n",
       ":   0.983442870563855\n",
       "$lambda\n",
       ":   2.98979504892541\n",
       "$min_child_weight\n",
       ":   2\n",
       "$colsample_bytree\n",
       ":   0.39119254149684\n",
       "$subsample\n",
       ":   0.659285381001271\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$eta\n",
       "[1] 0.2901334\n",
       "\n",
       "$max_depth\n",
       "[1] 8\n",
       "\n",
       "$alpha\n",
       "[1] 0.9834429\n",
       "\n",
       "$lambda\n",
       "[1] 2.989795\n",
       "\n",
       "$min_child_weight\n",
       "[1] 2\n",
       "\n",
       "$colsample_bytree\n",
       "[1] 0.3911925\n",
       "\n",
       "$subsample\n",
       "[1] 0.6592854\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>auc.test.mean</dt>\n",
       "\t\t<dd>0.907410435181575</dd>\n",
       "\t<dt>acc.test.mean</dt>\n",
       "\t\t<dd>0.8686117467582</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[auc.test.mean] 0.907410435181575\n",
       "\\item[acc.test.mean] 0.8686117467582\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "auc.test.mean\n",
       ":   0.907410435181575acc.test.mean\n",
       ":   0.8686117467582\n",
       "\n"
      ],
      "text/plain": [
       "auc.test.mean acc.test.mean \n",
       "    0.9074104     0.8686117 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res$x\n",
    "res$y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Then we could generate a new Learner with optimal hyperparameter settings and __retrain__ it on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner classif.xgboost from package xgboost\n",
       "Type: classif\n",
       "Name: eXtreme Gradient Boosting; Short name: xgboost\n",
       "Class: classif.xgboost\n",
       "Properties: twoclass,multiclass,numerics,factors,prob,weights,missings,featimp\n",
       "Predict-Type: prob\n",
       "Hyperparameters: nrounds=100,verbose=FALSE,objective=binary:logistic,eta=0.29,max_depth=8,alpha=0.983,lambda=2.99,min_child_weight=2,colsample_bytree=0.391,subsample=0.659\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn_opt <- setHyperPars(lrn, par.vals=res$x)\n",
    "lrn_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can inspect all points evaluated during the searching and output it as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HyperParsEffectData:\n",
       "Hyperparameters: eta,max_depth,alpha,lambda,min_child_weight,colsample_bytree,subsample\n",
       "Measures: auc.test.mean,acc.test.mean\n",
       "Optimizer: TuneControlRandom\n",
       "Nested CV Used: FALSE\n",
       "[1] \"Partial dependence requested\"\n",
       "Snapshot of data:\n",
       "        eta max_depth      alpha   lambda min_child_weight colsample_bytree\n",
       "1 0.3905567         6 0.12441539 2.482658                3        0.6776513\n",
       "2 0.3133254         7 0.04480111 2.080678                5        0.5210854\n",
       "3 0.2825981         8 0.76159505 1.010454                4        0.3594741\n",
       "4 0.1594541         7 0.51196954 2.987880                3        0.5246644\n",
       "5 0.3990977         5 0.68971964 2.874786                6        0.3727439\n",
       "6 0.3720453         7 0.20920194 2.053653                5        0.3369490\n",
       "  subsample auc.test.mean acc.test.mean iteration exec.time\n",
       "1 0.7973827     0.8960173     0.8510381         1      0.98\n",
       "2 0.6993547     0.9023835     0.8655484         2      1.03\n",
       "3 0.8383479     0.9021821     0.8647926         3      0.89\n",
       "4 0.7387139     0.9045491     0.8663164         4      1.03\n",
       "5 0.7662496     0.9021733     0.8655536         5      0.72\n",
       "6 0.7266416     0.9069703     0.8663112         6      0.79"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generateHyperParsEffectData(res, partial.dep = TRUE)\n",
    "perf_path <- as.data.frame(res$opt.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 Predicting\n",
    "- In Step 6 we already got the learner with best hyperparameter setting, now we need to __retrain__ the optimal model on the dataset and __predict__ it on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt_model <- train(lrn_opt, dataset)\n",
    "opt_pred <- predict(opt_model, dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We could use slot `$data` to access the prediction, also we could convert the object to dataframe directly. But pay attention to the columns in output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction1 <- opt_pred$data\n",
    "prediction2 <- as.data.frame(opt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>truth</th><th scope=col>prob.0</th><th scope=col>prob.1</th><th scope=col>response</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1         </td><td>0         </td><td>0.88643140</td><td>0.11356860</td><td>0         </td></tr>\n",
       "\t<tr><td>2         </td><td>1         </td><td>0.03790230</td><td>0.96209770</td><td>1         </td></tr>\n",
       "\t<tr><td>3         </td><td>0         </td><td>0.94110041</td><td>0.05889959</td><td>0         </td></tr>\n",
       "\t<tr><td>4         </td><td>0         </td><td>0.76211266</td><td>0.23788734</td><td>0         </td></tr>\n",
       "\t<tr><td>5         </td><td>1         </td><td>0.02898335</td><td>0.97101665</td><td>1         </td></tr>\n",
       "\t<tr><td>6         </td><td>1         </td><td>0.80719936</td><td>0.19280064</td><td>0         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " id & truth & prob.0 & prob.1 & response\\\\\n",
       "\\hline\n",
       "\t 1          & 0          & 0.88643140 & 0.11356860 & 0         \\\\\n",
       "\t 2          & 1          & 0.03790230 & 0.96209770 & 1         \\\\\n",
       "\t 3          & 0          & 0.94110041 & 0.05889959 & 0         \\\\\n",
       "\t 4          & 0          & 0.76211266 & 0.23788734 & 0         \\\\\n",
       "\t 5          & 1          & 0.02898335 & 0.97101665 & 1         \\\\\n",
       "\t 6          & 1          & 0.80719936 & 0.19280064 & 0         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "id | truth | prob.0 | prob.1 | response | \n",
       "|---|---|---|---|---|---|\n",
       "| 1          | 0          | 0.88643140 | 0.11356860 | 0          | \n",
       "| 2          | 1          | 0.03790230 | 0.96209770 | 1          | \n",
       "| 3          | 0          | 0.94110041 | 0.05889959 | 0          | \n",
       "| 4          | 0          | 0.76211266 | 0.23788734 | 0          | \n",
       "| 5          | 1          | 0.02898335 | 0.97101665 | 1          | \n",
       "| 6          | 1          | 0.80719936 | 0.19280064 | 0          | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  id truth prob.0     prob.1     response\n",
       "1 1  0     0.88643140 0.11356860 0       \n",
       "2 2  1     0.03790230 0.96209770 1       \n",
       "3 3  0     0.94110041 0.05889959 0       \n",
       "4 4  0     0.76211266 0.23788734 0       \n",
       "5 5  1     0.02898335 0.97101665 1       \n",
       "6 6  1     0.80719936 0.19280064 0       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(prediction1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>truth</th><th scope=col>prob.0</th><th scope=col>prob.1</th><th scope=col>response</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1         </td><td>0         </td><td>0.88643140</td><td>0.11356860</td><td>0         </td></tr>\n",
       "\t<tr><td>2         </td><td>1         </td><td>0.03790230</td><td>0.96209770</td><td>1         </td></tr>\n",
       "\t<tr><td>3         </td><td>0         </td><td>0.94110041</td><td>0.05889959</td><td>0         </td></tr>\n",
       "\t<tr><td>4         </td><td>0         </td><td>0.76211266</td><td>0.23788734</td><td>0         </td></tr>\n",
       "\t<tr><td>5         </td><td>1         </td><td>0.02898335</td><td>0.97101665</td><td>1         </td></tr>\n",
       "\t<tr><td>6         </td><td>1         </td><td>0.80719936</td><td>0.19280064</td><td>0         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " id & truth & prob.0 & prob.1 & response\\\\\n",
       "\\hline\n",
       "\t 1          & 0          & 0.88643140 & 0.11356860 & 0         \\\\\n",
       "\t 2          & 1          & 0.03790230 & 0.96209770 & 1         \\\\\n",
       "\t 3          & 0          & 0.94110041 & 0.05889959 & 0         \\\\\n",
       "\t 4          & 0          & 0.76211266 & 0.23788734 & 0         \\\\\n",
       "\t 5          & 1          & 0.02898335 & 0.97101665 & 1         \\\\\n",
       "\t 6          & 1          & 0.80719936 & 0.19280064 & 0         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "id | truth | prob.0 | prob.1 | response | \n",
       "|---|---|---|---|---|---|\n",
       "| 1          | 0          | 0.88643140 | 0.11356860 | 0          | \n",
       "| 2          | 1          | 0.03790230 | 0.96209770 | 1          | \n",
       "| 3          | 0          | 0.94110041 | 0.05889959 | 0          | \n",
       "| 4          | 0          | 0.76211266 | 0.23788734 | 0          | \n",
       "| 5          | 1          | 0.02898335 | 0.97101665 | 1          | \n",
       "| 6          | 1          | 0.80719936 | 0.19280064 | 0          | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  id truth prob.0     prob.1     response\n",
       "1 1  0     0.88643140 0.11356860 0       \n",
       "2 2  1     0.03790230 0.96209770 1       \n",
       "3 3  0     0.94110041 0.05889959 0       \n",
       "4 4  0     0.76211266 0.23788734 0       \n",
       "5 5  1     0.02898335 0.97101665 1       \n",
       "6 6  1     0.80719936 0.19280064 0       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To access the probabilities and true labels directly, we need to use function `getPredictionTruth()` and `getPredictionProbabilities()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 0\n",
       "4. 0\n",
       "5. 1\n",
       "6. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 1 0 0 1 1\n",
       "Levels: 0 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_label <- getPredictionTruth(opt_pred)\n",
    "head(true_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0.113568603992462</li>\n",
       "\t<li>0.962097704410553</li>\n",
       "\t<li>0.0588995926082134</li>\n",
       "\t<li>0.237887337803841</li>\n",
       "\t<li>0.971016645431519</li>\n",
       "\t<li>0.192800641059875</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.113568603992462\n",
       "\\item 0.962097704410553\n",
       "\\item 0.0588995926082134\n",
       "\\item 0.237887337803841\n",
       "\\item 0.971016645431519\n",
       "\\item 0.192800641059875\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.113568603992462\n",
       "2. 0.962097704410553\n",
       "3. 0.0588995926082134\n",
       "4. 0.237887337803841\n",
       "5. 0.971016645431519\n",
       "6. 0.192800641059875\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.11356860 0.96209770 0.05889959 0.23788734 0.97101665 0.19280064"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_class <- opt_pred$task.desc$positive\n",
    "pred_prob <- getPredictionProbabilities(opt_pred, cl=positive_class)\n",
    "head(pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 Calculating performance\n",
    "#### Based on the `true_label` and `pred_prob` vector, we could calculate whatever we want by the `ROCR` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced tuning: create custom measure\n",
    "#### Using precision at given recall as measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_custom_pr_measure <- function(recall_perc=5, name_str=\"pr5\"){\n",
    "  \n",
    "  find_prec_at_recall <- function(pred, recall_perc=5){\n",
    "    \n",
    "    positive_class <- pred$task.desc$positive\n",
    "    prob <- getPredictionProbabilities(pred, cl=positive_class)\n",
    "    truth <- getPredictionTruth(pred)\n",
    "    \n",
    "    aucobj <- ROCR::prediction(prob, truth) \n",
    "    \n",
    "    ppvRec <- ROCR::performance(aucobj, 'ppv', 'sens')\n",
    "    \n",
    "    tarPPV <- ppvRec@y.values[[1]][which.min(abs(ppvRec@x.values[[1]]-recall_perc*0.01))]\n",
    "    #selRec <- ppvRec@x.values[[1]][which.min(abs(ppvRec@x.values[[1]]-recall_perc*0.01))]\n",
    "    return(tarPPV)\n",
    "    }\n",
    "  \n",
    "  name <- paste(\"Precision at \", as.character(recall_perc),\"%\",\" recall\", sep='')\n",
    "  \n",
    "  custom_measure <- makeMeasure(\n",
    "    id = name_str, \n",
    "    name = name,\n",
    "    properties = c(\"classif\", \"req.prob\", \"req.truth\"),\n",
    "    minimize = FALSE, best = 1, worst = 0,\n",
    "    extra.args = list(\"threshold\" = recall_perc),\n",
    "    fun = function(task, model, pred, feats, extra.args) {\n",
    "      find_prec_at_recall(pred, extra.args$threshold)\n",
    "    }\n",
    "  )\n",
    "  custom_measure\n",
    "}\n",
    "\n",
    "pr20 <- make_custom_pr_measure(20, \"pr20\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in parallelStart(mode = MODE_SOCKET, cpus = cpus, socket.hosts = socket.hosts, :\n",
      "\"Parallelization was not stopped, doing it now.\"Stopped parallelization. All cleaned up.\n",
      "Starting parallelization in mode=socket with cpus=4.\n",
      "[Tune] Started tuning learner classif.xgboost for parameter set:\n",
      "                    Type len Def       Constr Req Tunable Trafo\n",
      "eta              numeric   -   -  0.15 to 0.4   -    TRUE     -\n",
      "max_depth        integer   -   -       3 to 8   -    TRUE     -\n",
      "alpha            numeric   -   -       0 to 1   -    TRUE     -\n",
      "lambda           numeric   -   -    0.25 to 3   -    TRUE     -\n",
      "min_child_weight integer   -   -       2 to 6   -    TRUE     -\n",
      "colsample_bytree numeric   -   -   0.3 to 0.7   -    TRUE     -\n",
      "subsample        numeric   -   - 0.65 to 0.95   -    TRUE     -\n",
      "With control class: TuneControlRandom\n",
      "Imputation value: -0Imputation value: -0Imputation value: -0\n",
      "Exporting objects to slaves for mode socket: .mlr.slave.options\n",
      "Mapping in parallel: mode = socket; cpus = 4; elements = 30.\n",
      "[Tune] Result: eta=0.241; max_depth=4; alpha=0.978; lambda=2.77; min_child_weight=4; colsample_bytree=0.546; subsample=0.755 : pr20.test.mean=   1,auc.test.mean=0.903,acc.test.mean=0.868\n",
      "Stopped parallelization. All cleaned up.\n"
     ]
    }
   ],
   "source": [
    "parallelStartSocket(num_cores, level=\"mlr.tuneParams\")\n",
    "\n",
    "# Cluster negatives to pos_n numbers with hierarchical clustering\n",
    "res2 <- tuneParams(lrn, dataset, resampling=cv, par.set=ps, control=ctrl, \n",
    "                  show.info=T, measures=list(pr20, auc, acc))\n",
    "parallelStop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tune result:\n",
       "Op. pars: eta=0.241; max_depth=4; alpha=0.978; lambda=2.77; min_child_weight=4; colsample_bytree=0.546; subsample=0.755\n",
       "pr20.test.mean=   1,auc.test.mean=0.903,acc.test.mean=0.868"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
